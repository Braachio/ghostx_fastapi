from fastapi import UploadFile, Form, File, APIRouter
from fastapi.responses import JSONResponse
from io import StringIO
import pandas as pd
import hashlib

from utils.supabase_client import supabase
from utils.sanitize import sanitize_for_json
from utils.calculate import calculate_distance, convert_speed_to_kmph
from utils.corner_exit_analysis import analyze_corner_exit_and_feedback
from services.purification import remove_straight_sections, correct_autoblip_throttle
from services.insert import extract_value, chunked_insert, chunked_insert_lap_raw, fetch_all_controls, fetch_all_vehicle_status
from services.analyze_sector_times import upload_sector_results, get_sector_summary


router = APIRouter()

def deduplicate_columns(columns):
    seen = {}
    result = []
    for col in columns:
        col_lower = col.strip().lower()
        if col_lower in seen:
            seen[col_lower] += 1
            col_lower = f"{col_lower}_{seen[col_lower]}"
        else:
            seen[col_lower] = 0
        result.append(col_lower)
    return result

def generate_lap_hash(df: pd.DataFrame) -> str:
    data_str = df.to_csv(index=False)
    return hashlib.sha256(data_str.encode()).hexdigest()

@router.post("/analyze-motec-csv")
async def analyze_motec_csv(
    file: UploadFile = File(...),
    user_id: str = Form(...),
    save: bool = Form(False),
    weather: str = Form(None),
    air_temp: float = Form(None),
    track_temp: float = Form(None)
):
    try:
        content = await file.read()
        text = content.decode("utf-8", errors="ignore")
        lines = text.splitlines()
        if len(lines) > 15:
            lines.pop(15)

        track_name = extract_value(lines, "Venue")
        car_name = extract_value(lines, "Vehicle")

        df = pd.read_csv(StringIO("\n".join(lines[14:])), on_bad_lines="skip", low_memory=False)
        df.columns = deduplicate_columns(df.columns)

        if "time" not in df.columns:
            return JSONResponse(status_code=400, content={"error": "'time' ì—´ì´ ì—†ìŒ"})

        for col in df.columns:
            df[col] = df[col].astype(str).str.replace(r"[a-zA-Z%/]+", "", regex=True)

        df = df.apply(pd.to_numeric, errors="coerce").dropna()
        df = df[[col for col in df.columns if not col.startswith("time_")]]

        if 'distance' not in df.columns:
            df = calculate_distance(df)

        df = convert_speed_to_kmph(df)

        # âœ… ì—¬ê¸°ì„œ ë¶„ë¦¬
        control_cols = ["time", "throttle", "brake", "steerangle", "speed", "rpms", "gear", "distance"]
        control_cols = [col for col in control_cols if col in df.columns]
        control_df = df[control_cols].copy()

        vehicle_cols = ["time"] + [col for col in df.columns if col not in control_cols and col != "time"]
        vehicle_df = df[vehicle_cols].copy()



        df, fixed_count = correct_autoblip_throttle(df)
        print(f"ğŸ› ï¸ ì˜¤í† ë¸”ë¦½ ë˜ëŠ” ë¸Œë ˆì´í¬ 100 ì¡°ê±´ìœ¼ë¡œ ìŠ¤ë¡œí‹€ ë³´ì •ëœ í–‰ ìˆ˜: {fixed_count}")
        df = remove_straight_sections(df)

        if not isinstance(df, pd.DataFrame):
            raise ValueError(f"remove_straight_sections() ê²°ê³¼ ì˜¤ë¥˜: {df}")

        if "gear" in df.columns:
            df["gear"] = pd.to_numeric(df["gear"], errors="coerce").fillna(0).astype(int)

        graph_keys = ["time", "throttle", "brake", "steerangle", "gear", "speed"]
        graph_data = df[[key for key in graph_keys if key in df.columns]].to_dict(orient="records")
        sector_results = get_sector_summary(df)

        # âœ… ì¤‘ë³µ í™•ì¸
        lap_hash = generate_lap_hash(df)

        if save:
            existing = supabase.table("lap_meta").select("id").eq("hash", lap_hash).execute()
            if existing.data:
                return JSONResponse(status_code=409, content={"error": "âŒ ì¤‘ë³µëœ ë© ë°ì´í„°ì…ë‹ˆë‹¤."})

            meta_resp = supabase.table("lap_meta").insert({
                "user_id": user_id,
                "track": track_name,
                "car": car_name,
                "weather": weather,
                "air_temp": air_temp,
                "track_temp": track_temp,
                "hash": lap_hash
            }).execute()
            lap_id = meta_resp.data[0]["id"]

            control_cols = ["time", "throttle", "brake", "steerangle", "speed", "rpms", "gear", "distance"]
            control_cols = [col for col in control_cols if col in df.columns]
            df["lap_id"] = lap_id

            chunked_insert("lap_controls", df[control_cols + ["lap_id"]].to_dict(orient="records"))

            print(f"ğŸ” ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {len(df)}")
            inserted = supabase.table("lap_controls").select("id").eq("lap_id", lap_id).execute()
            print(f"âœ… ì €ì¥ëœ lap_controls ìˆ˜: {len(inserted.data) if inserted.data else 0}")

            vehicle_cols = [col for col in df.columns if col not in control_cols + ["lap_id", "time"]]
            chunked_insert("lap_vehicle_status", df[["time"] + vehicle_cols + ["lap_id"]].to_dict(orient="records"))

            chunked_insert_lap_raw(lap_id, df)

            upload_sector_results(supabase, lap_id, user_id, track_name, df)

            # âœ… ì½”ë„ˆ íƒˆì¶œ êµ¬ê°„ ë¶„ì„
            exit_segments = analyze_corner_exit_and_feedback(control_df, vehicle_df)

            return {
                "status": "âœ… ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ",
                "track": track_name,
                "car": car_name,
                "data": graph_data,
                "sector_results": sector_results,
                "corner_exit_analysis": exit_segments
            }

        return {
            "status": "âœ… ë¶„ì„ ì™„ë£Œ (ì €ì¥ ì•ˆ í•¨)",
            "track": track_name,
            "car": car_name,
            "data": graph_data,
            "sector_results": sector_results,
            "corner_exit_analysis": exit_segments
        }

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"ë¶„ì„ ì‹¤íŒ¨: {repr(e)}"})

@router.get("/lap/{lap_id}")
def get_lap_data(lap_id: str):
    # lap_meta ì •ë³´ ì¡°íšŒ
    meta = supabase.table("lap_meta").select("*").eq("id", lap_id).single().execute().data
    if not meta:
        return JSONResponse(status_code=404, content={"error": "ë© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

    # lap_controls ê°€ì ¸ì˜¤ê¸°
    controls = fetch_all_controls(lap_id)
    vehicle = fetch_all_vehicle_status(lap_id)

    try:
        sector_results = supabase.table("sector_results").select("*").eq("lap_id", lap_id).execute().data
    except Exception as e:
        print(f"âŒ sector_results ì¡°íšŒ ì‹¤íŒ¨: {repr(e)}")
        sector_results = []

    # âœ… ìì—°ì–´ í”¼ë“œë°± ì¶”ê°€ ì²˜ë¦¬
    try:
        df_controls = pd.DataFrame(controls)
        df_vehicle = pd.DataFrame(vehicle)

        df = pd.merge(df_controls, df_vehicle, on="time", how="inner")

        required_columns = [
            "steerangle", "throttle",
            "wheel_speed_lf", "wheel_speed_rf",
            "wheel_speed_lr", "wheel_speed_rr"
        ]

        if all(col in df.columns for col in required_columns):
            corner_feedback = analyze_corner_exit_and_feedback(controls, vehicle)
        else:
            print("âš ï¸ ì½”ë„ˆ ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•¨: {[col for col in required_columns if col not in df.columns]}")
            corner_feedback = []
    except Exception as e:
        print(f"âŒ ì½”ë„ˆ í”¼ë“œë°± ë¶„ì„ ì‹¤íŒ¨: {repr(e)}")
        corner_feedback = []

    return sanitize_for_json({
        "track": meta["track"],
        "car": meta["car"],
        "data": controls,
        "sector_results": sector_results,
        "corner_exit_analysis": corner_feedback
    })

